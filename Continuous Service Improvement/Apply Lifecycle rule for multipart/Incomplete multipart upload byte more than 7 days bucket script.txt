import boto3
import json
from datetime import datetime
from botocore.exceptions import ClientError

ROLE_NAME = "OrganizationAccountAccessRole"  # Customize if needed
LIFECYCLE_ID = "AbortMultipartUploadsAfter7Days"

def assume_role(account_id, role_name):
    sts = boto3.client('sts')
    try:
        response = sts.assume_role(
            RoleArn=f"arn:aws:iam::{account_id}:role/{role_name}",
            RoleSessionName="LifecycleUpdateSession"
        )
        return {
            "AccessKeyId": response["Credentials"]["AccessKeyId"],
            "SecretAccessKey": response["Credentials"]["SecretAccessKey"],
            "SessionToken": response["Credentials"]["SessionToken"]
        }
    except ClientError as e:
        print(f"[ERROR] Failed to assume role in {account_id}: {e}")
        return None

def update_lifecycle_policy(bucket_name, s3_client):
    try:
        existing = s3_client.get_bucket_lifecycle_configuration(Bucket=bucket_name)
        rules = existing.get("Rules", [])
    except ClientError as e:
        if e.response["Error"]["Code"] == "NoSuchLifecycleConfiguration":
            rules = []
        else:
            print(f"[ERROR] Failed to fetch lifecycle config for {bucket_name}: {e}")
            return

    # Check if a rule for aborting multipart uploads already exists
    for rule in rules:
        if rule.get("ID") == LIFECYCLE_ID:
            print(f"[INFO] Lifecycle rule already exists in {bucket_name}, skipping.")
            return

    # Append new rule
    rules.append({
        "ID": LIFECYCLE_ID,
        "Status": "Enabled",
        "Filter": {"Prefix": ""},
        "AbortIncompleteMultipartUpload": {"DaysAfterInitiation": 7}
    })

    try:
        s3_client.put_bucket_lifecycle_configuration(
            Bucket=bucket_name,
            LifecycleConfiguration={"Rules": rules}
        )
        print(f"[SUCCESS] Lifecycle rule added to {bucket_name}")
    except ClientError as e:
        print(f"[ERROR] Failed to update lifecycle config for {bucket_name}: {e}")

def main(input_file):
    with open(input_file, "r") as file:
        for line in file:
            line = line.strip()
            if not line or line.startswith("#"):
                continue
            try:
                account_id, bucket_name = line.split()
            except ValueError:
                print(f"[SKIP] Invalid line format: '{line}' (expected: ACCOUNT_ID BUCKET_NAME)")
                continue

            print(f"\n[INFO] Processing Account: {account_id}, Bucket: {bucket_name}")
            creds = assume_role(account_id, ROLE_NAME)
            if not creds:
                continue

            s3_client = boto3.client(
                "s3",
                aws_access_key_id=creds["AccessKeyId"],
                aws_secret_access_key=creds["SecretAccessKey"],
                aws_session_token=creds["SessionToken"]
            )

            update_lifecycle_policy(bucket_name, s3_client)

if __name__ == "__main__":
    main("input.txt")
